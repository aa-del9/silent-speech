{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 23:39:23.014592: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 23:39:23.066692: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 23:39:23.279475: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 23:39:23.279532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 23:39:23.318184: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 23:39:23.397639: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 23:39:23.398686: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 23:39:24.810375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#importing stuff and setting global variables\n",
    "import cv2 as cv# for realtime processing\n",
    "import math\n",
    "import mediapipe as mp# fro AI \n",
    "#import pyautogui as py#yeh screenshot k liay hai\n",
    "# from mediapipe_model_maker import gesture_recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Code below i for creating the task or i would say a medol instance for recognizing guestures for a curstom data set\n",
    "First piece of code is to load data from a folder into variable data and than split it into testing and training data\n",
    "Next peice of code of is Training data than testing data data and finally exporting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES_PATH = \"rps_data_sample\"\n",
    "# data = gesture_recognizer.Dataset.from_folder(\n",
    "#     dirname=IMAGES_PATH,\n",
    "#     hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
    "# )\n",
    "# # Split the archive into training, validation and test dataset.\n",
    "# train_data, rest_data = data.split(0.8)\n",
    "# validation_data, test_data = rest_data.split(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams = gesture_recognizer.HParams(export_dir=\"rock_paper_scissors_model\")\n",
    "# options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)\n",
    "# model = gesture_recognizer.GestureRecognizer.create(\n",
    "#     train_data=train_data,\n",
    "#     validation_data=validation_data,\n",
    "#     options=options\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, acc = model.evaluate(test_data, batch_size=1)\n",
    "# print(f\"Test loss:{loss}, Test accuracy:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.export_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is for drawing landmarks on real time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "def hand_detector(frame,holistic):\n",
    "    frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    results = holistic.process(frame_rgb)\n",
    "\n",
    "    ## for drawing left hand\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2))\n",
    "        \n",
    "    ## From drawing right hand\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=2))\n",
    "    \n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code bellow is load the model and use it for real-time and making it ready for real time camera application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701628766.319474   14123 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1701628766.323925   14183 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) Xe Graphics (TGL GT2)\n",
      "W0000 00:00:1701628766.331641   14123 gesture_recognizer_graph.cc:129] Hand Gesture Recognizer contains CPU only ops. Sets HandGestureRecognizerGraph acceleration to Xnnpack.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "GestureRecognizer = mp.tasks.vision.GestureRecognizer\n",
    "GestureRecognizerOptions = mp.tasks.vision.GestureRecognizerOptions\n",
    "GestureRecognizerResult = mp.tasks.vision.GestureRecognizerResult\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "result_name = [None,0]\n",
    "def print_result(result: GestureRecognizerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "     #print('gesture recognition result: {}'.format(result))\n",
    "     if len(result.gestures) and len(result.gestures[0]):\n",
    "      gesture = result.gestures[0][0]\n",
    "      if result_name[0] != gesture.category_name:\n",
    "         result_name[0] = gesture.category_name\n",
    "         result_name[1] = 0\n",
    "      else:\n",
    "         result_name[1] += 1\n",
    "      print(gesture.category_name,result_name[1])\n",
    "        \n",
    "     else:\n",
    "        result_name[0] = None\n",
    "        result_name[1] = 0\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "options = GestureRecognizerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='exported_model/gesture_recognizer.task'),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,result_callback=print_result\n",
    "    )\n",
    "recognizer =  GestureRecognizer.create_from_options(options) \n",
    "timestamp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701628766.442077   14123 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1701628766.443724   14202 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) Xe Graphics (TGL GT2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B 0\n",
      "B 1\n",
      "B 2\n",
      "B 3\n",
      "B 4\n",
      "B 5\n",
      "B 6\n",
      "B 7\n",
      "B 8\n",
      "B 9\n",
      "B 10\n",
      "B 11\n",
      "B 12\n",
      "B 13\n",
      "B 14\n",
      "B 15\n",
      "B 16\n",
      "B 17\n",
      "B 18\n",
      "B 19\n",
      "B 20\n",
      "B 21\n",
      "B 22\n",
      "B 23\n",
      "B 24\n",
      "B 25\n",
      "B 26\n",
      "C 0\n",
      "E 0\n",
      "A 0\n",
      "A 1\n",
      "A 2\n",
      "A 3\n",
      "A 4\n",
      "A 5\n",
      "A 6\n",
      "A 7\n",
      "A 8\n",
      "A 9\n",
      "A 10\n",
      "A 11\n",
      "A 12\n",
      "A 13\n",
      "A 14\n",
      "A 15\n",
      "A 16\n",
      "A 17\n",
      "A 18\n",
      "A 19\n",
      "A 20\n",
      "A 21\n",
      "A 22\n",
      "A 23\n",
      "A 24\n",
      "A 25\n",
      "A 26\n",
      "A 27\n",
      "A 28\n",
      "A 29\n",
      "A 30\n",
      "A 31\n",
      "A 32\n",
      "N 0\n",
      "K 0\n",
      "K 1\n",
      "K 2\n",
      "K 3\n",
      "K 4\n",
      "K 5\n",
      "K 6\n",
      "K 7\n",
      "K 8\n",
      "K 9\n",
      "K 10\n",
      "K 11\n",
      "K 12\n",
      "K 13\n",
      "K 14\n",
      "K 15\n",
      "K 16\n",
      "K 17\n",
      "K 18\n",
      "K 19\n",
      "K 20\n",
      "K 21\n",
      "K 22\n",
      "K 23\n",
      "K 24\n",
      "K 25\n",
      "K 26\n",
      "K 27\n",
      "O 0\n",
      "C 0\n",
      "C 1\n",
      "C 2\n",
      "C 3\n",
      "C 4\n",
      "C 5\n",
      "C 6\n",
      "C 7\n",
      "C 8\n",
      "C 9\n",
      "C 10\n",
      "C 11\n",
      "C 12\n",
      "C 13\n",
      "C 14\n",
      "C 15\n",
      "C 16\n",
      "C 17\n",
      "C 18\n",
      "C 19\n",
      "C 20\n",
      "C 21\n",
      "C 22\n",
      "C 23\n",
      "C 24\n",
      "C 25\n",
      "C 26\n",
      "C 27\n",
      "C 28\n",
      "C 29\n",
      "C 30\n",
      "C 31\n",
      "C 32\n",
      "C 33\n",
      "C 34\n",
      "C 35\n",
      "C 36\n",
      "C 37\n",
      "C 38\n",
      "C 39\n",
      "C 40\n",
      "C 41\n",
      "C 42\n",
      "C 43\n",
      "C 44\n",
      "C 45\n",
      "C 46\n",
      "C 47\n",
      "C 48\n",
      "C 49\n",
      "C 50\n",
      "C 51\n",
      "C 52\n",
      "C 53\n",
      "C 54\n",
      "B 0\n",
      "B 1\n",
      "B 2\n",
      "B 3\n",
      "B 4\n",
      "B 5\n",
      "B 6\n",
      "B 7\n",
      "B 8\n",
      "B 9\n",
      "B 10\n",
      "B 11\n",
      "B 12\n",
      "B 13\n",
      "B 14\n",
      "B 15\n",
      "B 16\n",
      "B 17\n",
      "B 18\n",
      "B 19\n",
      "B 20\n",
      "B 21\n",
      "B 22\n",
      "B 23\n",
      "B 24\n",
      "B 25\n",
      "B 26\n",
      "B 27\n",
      "B 28\n",
      "B 29\n",
      "B 30\n",
      "B 31\n",
      "B 32\n",
      "B 33\n",
      "B 34\n",
      "B 35\n",
      "B 36\n",
      "B 37\n",
      "O 0\n",
      "B 0\n",
      "B 1\n",
      "B 2\n",
      "B 3\n",
      "B 4\n",
      "B 5\n",
      "B 6\n",
      "B 7\n",
      "B 8\n",
      "B 9\n",
      "B 10\n",
      "B 11\n",
      "B 12\n",
      "B 13\n",
      "B 14\n",
      "B 15\n",
      "B 16\n",
      "B 17\n",
      "B 18\n",
      "B 19\n",
      "B 20\n",
      "B 21\n",
      "B 22\n",
      "B 23\n",
      "B 24\n",
      "B 25\n",
      "B 26\n",
      "B 27\n",
      "B 28\n",
      "B 29\n",
      "B 30\n",
      "B 31\n",
      "C 0\n",
      "C 1\n",
      "C 2\n",
      "C 3\n",
      "C 4\n",
      "C 5\n",
      "C 6\n",
      "C 7\n",
      "C 8\n",
      "C 9\n",
      "C 10\n",
      "C 11\n",
      "C 12\n",
      "C 13\n",
      "C 14\n",
      "C 15\n",
      "C 16\n",
      "C 17\n",
      "C 18\n",
      "C 19\n",
      "C 20\n",
      "K 0\n",
      "K 1\n",
      "K 2\n",
      "K 3\n",
      "K 4\n",
      "K 5\n",
      "K 6\n",
      "K 7\n",
      "K 8\n",
      "K 9\n",
      "K 10\n",
      "K 11\n",
      "K 12\n",
      "K 13\n",
      "K 14\n",
      "K 15\n",
      "K 16\n",
      "V 0\n",
      "V 1\n",
      "V 2\n",
      "V 3\n",
      "V 4\n",
      "V 5\n",
      "V 6\n",
      "V 7\n",
      "V 8\n",
      "V 9\n",
      "V 10\n",
      "V 11\n",
      "V 12\n",
      "V 13\n",
      "V 14\n",
      "V 15\n",
      "V 16\n",
      "V 17\n",
      "V 18\n",
      "V 19\n",
      "V 20\n",
      "V 21\n",
      "V 22\n",
      "V 23\n",
      "V 24\n",
      "V 25\n",
      "V 26\n",
      "V 27\n",
      "V 28\n",
      "V 29\n",
      "V 30\n",
      "V 31\n",
      "V 32\n",
      "V 33\n",
      "V 34\n",
      "V 35\n",
      "V 36\n",
      "V 37\n",
      "V 38\n",
      "V 39\n",
      "V 40\n",
      "V 41\n",
      "U 0\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "O 0\n",
      "O 1\n",
      "O 2\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 9\n",
      " 10\n",
      " 11\n",
      " 12\n",
      " 13\n",
      " 14\n",
      " 15\n",
      " 16\n",
      " 17\n",
      " 18\n",
      " 19\n",
      " 20\n",
      " 21\n",
      " 22\n",
      " 23\n",
      " 24\n",
      " 25\n",
      " 26\n",
      " 27\n",
      " 28\n",
      " 29\n",
      "A 0\n"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.7, min_tracking_confidence=0.8)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT,720)\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH,1080)\n",
    "while cap.isOpened():\n",
    "    timestamp += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    recognition_result = recognizer.recognize_async(mp_image,timestamp)\n",
    "    #print(result_name[0])\n",
    "\n",
    "    frame = hand_detector(frame,holistic)\n",
    "\n",
    "    cv.imshow(\"Hand Sign Detection\", frame )    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q') or (result_name[0] == \"scissors\" and result_name[1] > 6):\n",
    "        break\n",
    "\n",
    "    if result_name[0] == \"paper\" and result_name[1] > 6:\n",
    "        screenshot = py.screenshot()\n",
    "        screenshot.save(\"screenshot.png\")\n",
    "    \n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
